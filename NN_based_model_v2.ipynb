{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, TensorBoard, ReduceLROnPlateau,\n",
    "                                        CSVLogger, EarlyStopping)\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train/train_features_emotion_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df[['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
    "       '11', '12', '13', '14', '15', '16', '17']])\n",
    "y = pd.Series(df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the model with Conv1D and BiLSTM layers\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Conv1D layer (2048 filters, kernel size = 3, padding = 'same', with maxpooling)\n",
    "model.add(Conv1D(2048, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# # 2nd Conv1D layer (1024 filters, kernel size = 3, padding = 'same', with maxpooling)\n",
    "model.add(Conv1D(1024, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Conv1D layer (512 filters, kernel size = 3, padding = 'same', with maxpooling)\n",
    "model.add(Conv1D(512, kernel_size=3, strides=1,padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Adding Bidirectional LSTM layer\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))  # You can increase the number of units if required\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128)))  # You can increase the number of units if required\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Dense layer with 64 units\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Final Dense layer with 6 units for output (emotions)\n",
    "model.add(Dense(6, activation='softmax'))  # Output layer with 6 classes (emotions)\n",
    "\n",
    "# Compile the model using Adam optimizer and sparse_categorical_crossentropy loss\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "callbacks_defn = [ModelCheckpoint(filepath = 'best_weights_emotion_audio.h5', monitor='val_accuracy',\n",
    "                                       verbose=1, save_best_only=True,save_weights_only=False,mode='min'),\n",
    "                                       EarlyStopping(monitor='val_loss',min_delta =0.01, patience=25, mode='min', restore_best_weights=True),\n",
    "                                       ReduceLROnPlateau(monitor='val_loss', factor=0.75,patience=10, min_lr=0.000001)]\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, epochs=2000, batch_size=32, validation_data=(X_val, y_val), callbacks=callbacks_defn,\n",
    "                       verbose = 1,\n",
    "                       shuffle = True, )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions from one-hot encoded to label format\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
    "y_test_labels = y_test  # No need to convert y_test since we kept it as integers\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
